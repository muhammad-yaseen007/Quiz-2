{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Quiz-2**"
      ],
      "metadata": {
        "id": "wKBOgALplcmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform following tasks on the provided Reviews Dataset.\n",
        "* Drop words if not alphabets.\n",
        "* Tokenize the sentence.\n",
        "* Perform lemitization.\n",
        "* Vectorize using bigram and trigram techniques.\n",
        "* Apply Random Forest algorithm with 150 trees.\n",
        "* Evaluate overall accuracy of the model and class-wise precision ."
      ],
      "metadata": {
        "id": "m5VxQWNuli1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "# nltk.download('omw-1.4')\n",
        "\n",
        "data = pd.read_csv('reviews_dataset.csv')\n",
        "\n",
        "print(data.shape)\n",
        "print(data.head)\n",
        "news = data['news']\n",
        "type = data['type']\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "news = news.apply(preprocess_text)\n",
        "print(news)\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 3))\n",
        "X = vectorizer.fit_transform(news)\n",
        "\n",
        "print(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, type, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "r64UMWDGA2Bj",
        "outputId": "699c2d0b-093e-4421-d55c-ed33c448fe54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2225, 2)\n",
            "<bound method NDFrame.head of                                                    news      type\n",
            "0     China had role in Yukos split-up\\n \\n China le...  business\n",
            "1     Oil rebounds from weather effect\\n \\n Oil pric...  business\n",
            "2     Indonesia 'declines debt freeze'\\n \\n Indonesi...  business\n",
            "3     $1m payoff for former Shell boss\\n \\n Shell is...  business\n",
            "4     US bank in $515m SEC settlement\\n \\n Five Bank...  business\n",
            "...                                                 ...       ...\n",
            "2220  Microsoft launches its own search\\n \\n Microso...      tech\n",
            "2221  Warnings about junk mail deluge\\n \\n The amoun...      tech\n",
            "2222  Microsoft gets the blogging bug\\n \\n Software ...      tech\n",
            "2223  Gamers snap up new Sony PSP\\n \\n Gamers have b...      tech\n",
            "2224  Apple laptop is 'greatest gadget'\\n \\n The App...      tech\n",
            "\n",
            "[2225 rows x 2 columns]>\n",
            "0       china had role in yukos china lent russia to h...\n",
            "1       oil rebound from weather effect oil price reco...\n",
            "2       indonesia debt freeze indonesia no longer need...\n",
            "3       payoff for former shell bos shell is to pay to...\n",
            "4       u bank in sec settlement five bank of america ...\n",
            "                              ...                        \n",
            "2220    microsoft launch it own search microsoft ha un...\n",
            "2221    warning about junk mail deluge the amount of s...\n",
            "2222    microsoft get the blogging bug software giant ...\n",
            "2223    gamers snap up new sony psp gamers have bought...\n",
            "2224    apple laptop is gadget the apple powerbook ha ...\n",
            "Name: news, Length: 2225, dtype: object\n",
            "  (0, 147010)\t1\n",
            "  (0, 309437)\t1\n",
            "  (0, 611748)\t1\n",
            "  (0, 359891)\t1\n",
            "  (0, 874932)\t1\n",
            "  (0, 147065)\t1\n",
            "  (0, 417117)\t1\n",
            "  (0, 616220)\t1\n",
            "  (0, 771211)\t3\n",
            "  (0, 324703)\t1\n",
            "  (0, 734807)\t2\n",
            "  (0, 616339)\t2\n",
            "  (0, 297492)\t1\n",
            "  (0, 599761)\t1\n",
            "  (0, 724407)\t1\n",
            "  (0, 403084)\t1\n",
            "  (0, 874850)\t1\n",
            "  (0, 801708)\t1\n",
            "  (0, 503646)\t2\n",
            "  (0, 514335)\t1\n",
            "  (0, 301472)\t1\n",
            "  (0, 875000)\t1\n",
            "  (0, 386696)\t1\n",
            "  (0, 303866)\t1\n",
            "  (0, 92159)\t1\n",
            "  :\t:\n",
            "  (2224, 687127)\t1\n",
            "  (2224, 630165)\t1\n",
            "  (2224, 306436)\t1\n",
            "  (2224, 606943)\t1\n",
            "  (2224, 699192)\t1\n",
            "  (2224, 54568)\t1\n",
            "  (2224, 726057)\t1\n",
            "  (2224, 432755)\t1\n",
            "  (2224, 257928)\t1\n",
            "  (2224, 558618)\t1\n",
            "  (2224, 198341)\t1\n",
            "  (2224, 421322)\t1\n",
            "  (2224, 814266)\t1\n",
            "  (2224, 222693)\t1\n",
            "  (2224, 769527)\t1\n",
            "  (2224, 245789)\t1\n",
            "  (2224, 687128)\t1\n",
            "  (2224, 219985)\t1\n",
            "  (2224, 630166)\t1\n",
            "  (2224, 386800)\t1\n",
            "  (2224, 306437)\t1\n",
            "  (2224, 606944)\t1\n",
            "  (2224, 493627)\t1\n",
            "  (2224, 699193)\t1\n",
            "  (2224, 54569)\t1\n",
            "Overall Accuracy: 0.8471910112359551\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.80      0.93      0.86       115\n",
            "entertainment       0.93      0.60      0.73        72\n",
            "     politics       0.97      0.86      0.91        76\n",
            "        sport       0.76      1.00      0.86       102\n",
            "         tech       0.95      0.75      0.84        80\n",
            "\n",
            "     accuracy                           0.85       445\n",
            "    macro avg       0.88      0.83      0.84       445\n",
            " weighted avg       0.87      0.85      0.84       445\n",
            "\n"
          ]
        }
      ]
    }
  ]
}